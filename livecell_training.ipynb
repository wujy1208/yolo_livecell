{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5580f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "# from data_converter import *\n",
    "\n",
    "def convert_coco_json(image_folder, annotation_file, output_folder, keep_fn=None, use_segments=True):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_image_folder = os.path.join(output_folder, \"images\")\n",
    "    output_ann_folder = os.path.join(output_folder, \"labels\")\n",
    "    os.makedirs(output_image_folder, exist_ok=True)\n",
    "    os.makedirs(output_ann_folder, exist_ok=True)\n",
    "\n",
    "    # Load coco annotation\n",
    "    with open(annotation_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Create image dict\n",
    "    images = {\"%g\" % x[\"id\"]: x for x in data[\"images\"]}\n",
    "    # Create image-annotations dict\n",
    "    imgToAnns = defaultdict(list)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        imgToAnns[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    label_counter = Counter()\n",
    "    # Write labels file\n",
    "    # for img_id, anns in tqdm.tqdm(imgToAnns.items(), desc=f\"Annotations {annotation_file}\"):\n",
    "    for img_id, anns in imgToAnns.items():\n",
    "        img = images[\"%g\" % img_id]\n",
    "        h, w, f = img[\"height\"], img[\"width\"], img[\"file_name\"]\n",
    "        if keep_fn is not None and not keep_fn(f):\n",
    "            continue\n",
    "\n",
    "        bboxes = []\n",
    "        segments = []\n",
    "        for ann in anns:\n",
    "            if ann[\"iscrowd\"]:\n",
    "                continue\n",
    "            # The COCO box format is [top left x, top left y, width, height]\n",
    "            box = np.array(ann[\"bbox\"], dtype=np.float64)\n",
    "            box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "            box[[0, 2]] /= w  # normalize x\n",
    "            box[[1, 3]] /= h  # normalize y\n",
    "            if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                continue\n",
    "\n",
    "            cls = ann[\"category_id\"] - 1\n",
    "            label_counter[cls] += 1\n",
    "            box = [cls] + box.tolist()\n",
    "            if box not in bboxes:\n",
    "                bboxes.append(box)\n",
    "            # Segments\n",
    "            if use_segments:\n",
    "                if len(ann[\"segmentation\"]) > 1:\n",
    "                    s = merge_multi_segment(ann[\"segmentation\"])\n",
    "                    s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                else:\n",
    "                    s = [j for i in ann[\"segmentation\"] for j in i]  # all segments concatenated\n",
    "                    s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                s = [cls] + s\n",
    "                if s not in segments:\n",
    "                    segments.append(s)\n",
    "\n",
    "        # Write\n",
    "        src_img_path = os.path.join(image_folder, f)\n",
    "        new_img_path = os.path.join(output_image_folder, f)\n",
    "        new_ann_path = os.path.join(output_ann_folder, f\"{os.path.splitext(f)[0]}.txt\")\n",
    "\n",
    "        shutil.copy(src_img_path, new_img_path)   \n",
    "        with open(new_ann_path, \"w\") as file:\n",
    "            for i in range(len(bboxes)):\n",
    "                line = (*(segments[i] if use_segments else bboxes[i]),)  # cls, box or segments\n",
    "                file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")\n",
    "        \n",
    "    return label_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c6c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in train dataset: Counter({0: 1018576})\n",
      "Labels in val dataset: Counter({0: 181610})\n",
      "Labels in val dataset: Counter({0: 462261})\n"
     ]
    }
   ],
   "source": [
    "output_folder_train = \"./data_yolo/train\"\n",
    "label_counter_train = convert_coco_json(\n",
    "    image_folder=\"./data_coco/images/livecell_train_val_images\", \n",
    "    annotation_file=\"./data_coco/livecell_coco_train.json\", \n",
    "    output_folder=output_folder_train,\n",
    "    use_segments=True\n",
    ")\n",
    "print(f\"Labels in train dataset: {label_counter_train}\")\n",
    "\n",
    "output_folder_val = \"./data_yolo/val\"\n",
    "label_counter_val = convert_coco_json(\n",
    "    image_folder=\"./data_coco/images/livecell_train_val_images\", \n",
    "    annotation_file=\"./data_coco/livecell_coco_val.json\", \n",
    "    output_folder=output_folder_val,\n",
    "    use_segments=True\n",
    ")\n",
    "print(f\"Labels in val dataset: {label_counter_val}\")\n",
    "\n",
    "output_folder_test = \"./data_yolo/test\"\n",
    "label_counter_test = convert_coco_json(\n",
    "    image_folder=\"./data_coco/images/livecell_test_images\", \n",
    "    annotation_file=\"./data_coco/livecell_coco_test.json\", \n",
    "    output_folder=output_folder_test,\n",
    "    use_segments=True\n",
    ")\n",
    "print(f\"Labels in val dataset: {label_counter_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c449378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ./data_yolo/train/images\n",
      "val: ./data_yolo/val/images\n",
      "test: ./data_yolo/test/images\n",
      "nc: 1\n",
      "names: ['cell']\n"
     ]
    }
   ],
   "source": [
    "yaml_file = [\n",
    "    f\"train: {os.path.join(output_folder_train, 'images')}\",\n",
    "    f\"val: {os.path.join(output_folder_val, 'images')}\",\n",
    "    f\"test: {os.path.join(output_folder_test, 'images')}\",\n",
    "    f\"nc: 1\",\n",
    "    f\"names: {['cell']}\",\n",
    "]\n",
    "print(\"\\n\".join(yaml_file))\n",
    "\n",
    "with open(\"data_livecell.yaml\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(yaml_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b654e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:2 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:3 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=./data_livecell.yaml, epochs=10, time=None, patience=100, batch=48, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:1,2,3, workers=8, project=ckpts, name=livecell, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.1, scale=0.2, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ckpts/livecell\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n",
      "YOLOv8s-seg summary: 261 layers, 11790483 parameters, 11790467 gradients, 42.7 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /project/DPDS/Xiao_lab/shared/CondaEnv/hd_env/bin/python -m torch.distributed.run --nproc_per_node 3 --master_port 43513 /home2/s181141/.config/Ultralytics/DDP/_temp__ki67j5w46916156270736.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:2 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:3 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "Transferred 411/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/train/labels.cache... 3188 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3188/3188 [00:00<?, ?it/s]\r",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/train/labels.cache... 3188 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3188/3188 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/train/images/BV2_Phase_D4_2_02d12h00m_4.tif: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/train/images/BV2_Phase_D4_2_02d16h00m_4.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/val/labels.cache... 568 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 568/568 [00:00<?, ?it/s]\r",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/val/labels.cache... 568 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 568/568 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to ckpts/livecell/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.000375), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 24 dataloader workers\n",
      "Logging results to \u001b[1mckpts/livecell\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      16.9G      2.163      3.675      1.455      1.351       2401        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [01:55<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.718      0.453      0.575      0.325      0.677      0.406      0.512      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      17.6G      1.697       2.96     0.8449      1.112       2386        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:42<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.681      0.386      0.521      0.299      0.656      0.334      0.454      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      20.2G      1.657      2.842     0.8235      1.103       1200        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:41<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.691      0.377      0.514      0.292      0.665      0.316      0.423      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      26.5G      1.613      2.744     0.7876      1.079       1358        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:41<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.696      0.405      0.538      0.302       0.67      0.362      0.478      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      28.7G      1.599      2.672     0.7778      1.082       1348        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:42<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.797      0.486      0.625      0.369       0.77      0.458       0.58      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      18.5G      1.571       2.61     0.7637      1.068       1986        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:42<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.834      0.519      0.654      0.403      0.815        0.5      0.623      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      27.4G      1.553      2.614     0.7474      1.059       2756        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:42<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.839      0.521      0.658      0.421      0.824      0.506      0.635      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      25.6G      1.527      2.621     0.7321      1.049       2054        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:41<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.839      0.517      0.656      0.404      0.825      0.504      0.633       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      20.7G      1.545      2.565     0.7374      1.058       1580        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:43<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.819      0.518      0.652      0.414        0.8        0.5      0.622      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      25.6G      1.515      2.501     0.7182      1.048       1643        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:42<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:13<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.839      0.524      0.661      0.421      0.819      0.507      0.634      0.312\n",
      "\n",
      "10 epochs completed in 0.184 hours.\n",
      "Optimizer stripped from ckpts/livecell/weights/last.pt, 23.8MB\n",
      "Optimizer stripped from ckpts/livecell/weights/best.pt, 23.8MB\n",
      "\n",
      "Validating ckpts/livecell/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:2 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "                                                           CUDA:3 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11779987 parameters, 0 gradients, 42.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [01:25<00:00,  4.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.839      0.521      0.658      0.421      0.823      0.506      0.635      0.316\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data='./data_livecell.yaml', \n",
    "    project='ckpts',\n",
    "    name='livecell',\n",
    "    epochs=10,\n",
    "    batch=48,\n",
    "    imgsz=640,\n",
    "    device='cuda:1,2,3', # [1],\n",
    "    single_cls=False, # \n",
    "    label_smoothing=0.0,\n",
    "    overlap_mask=True,\n",
    "    mask_ratio=4,\n",
    "\n",
    "    #Augmentation parameters\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    degrees=0.0,  # (float) image rotation (+/- deg)\n",
    "    translate=0.1,  # (float) image translation (+/- fraction)\n",
    "    scale=0.2,  # (float) image scale (+/- gain)\n",
    "    shear=0.0,  # (float) image shear (+/- deg)\n",
    "    perspective=0.0,  # (float) image perspective (+/- fraction), range 0-0.001\n",
    "    flipud=0.5,  # (float) image flip up-down (probability)\n",
    "    fliplr=0.5,  # (float) image flip left-right (probability)\n",
    "    mosaic=1.0,  # (float) image mosaic (probability)\n",
    "    mixup=0.0,  # (float) image mixup (probability)\n",
    "    copy_paste=0.0,  # (float) segment copy-paste (probability)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f9f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on validation dataset:\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11779987 parameters, 0 gradients, 42.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/val/labels.cache... 568 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 568/56\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/12 [00:00<?/project/DPDS/Xiao_lab/shared/CondaEnv/hd_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:28<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        568     181540      0.839      0.521      0.658      0.423      0.818      0.503      0.631      0.306\n",
      "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 12.0ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell2\u001b[0m\n",
      "Evaluate on testing dataset:\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/labels.cache... 1512 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1512\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/Huh7_Phase_A12_2_03d04h00m_2.tif: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/MCF7_Phase_H4_1_00d00h00m_2.tif: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/SHSY5Y_Phase_A10_2_03d08h00m_2.tif: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/SKOV3_Phase_E4_2_02d16h00m_3.tif: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/SKOV3_Phase_E4_2_02d20h00m_3.tif: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/data_yolo/test/images/SKOV3_Phase_E4_2_03d00h00m_4.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   9%|â–‰         | 3/32 [00:41<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 4.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [02:31<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1512     453041       0.84      0.531      0.661      0.422      0.824      0.515      0.636      0.317\n",
      "Speed: 0.1ms preprocess, 4.4ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Overall model performance on the validation set\n",
    "# model = YOLO('./ckpts/livecell/weights/best.pt')\n",
    "print(\"Evaluate on validation dataset:\")\n",
    "val_stats = model.val(data='./data_livecell.yaml', device='cuda:1', split='val')\n",
    "\n",
    "print(\"Evaluate on testing dataset:\")\n",
    "test_stats = model.val(data='./data_livecell.yaml', device='cuda:1', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8e57c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A172': 32978, 'BT474': 32585, 'BV2': 89970, 'Huh7': 12552, 'MCF7': 96914, 'SHSY5Y': 75988, 'SkBr3': 65757, 'SKOV3': 55517}\n",
      "================\n",
      "A172: ./data_yolo_split/A172/images\n",
      "BT474: ./data_yolo_split/BT474/images\n",
      "BV2: ./data_yolo_split/BV2/images\n",
      "Huh7: ./data_yolo_split/Huh7/images\n",
      "MCF7: ./data_yolo_split/MCF7/images\n",
      "SHSY5Y: ./data_yolo_split/SHSY5Y/images\n",
      "SkBr3: ./data_yolo_split/SkBr3/images\n",
      "SKOV3: ./data_yolo_split/SKOV3/images\n",
      "train: ./data_yolo/train/images\n",
      "val: ./data_yolo/val/images\n",
      "test: ./data_yolo/test/images\n",
      "nc: 1\n",
      "names: ['cell']\n",
      "================\n",
      "Evaluate on testing dataset for each categories:\n",
      "================\n",
      "marker: A172\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/A172/labels.cache... 152 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:40<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        152      32978       0.76      0.657      0.709        0.4      0.779      0.666      0.721      0.369\n",
      "Speed: 0.2ms preprocess, 15.9ms inference, 0.0ms loss, 15.0ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell4\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: BT474\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/BT474/labels.cache... 168 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:50<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        168      32584      0.706      0.642      0.711      0.409      0.694      0.615      0.679      0.321\n",
      "Speed: 0.4ms preprocess, 11.0ms inference, 0.0ms loss, 25.5ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell5\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: BV2\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/BV2/labels.cache... 152 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:28<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        152      89966      0.969      0.383      0.628      0.443      0.902      0.356      0.583       0.27\n",
      "Speed: 0.1ms preprocess, 3.8ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell6\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: Huh7\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/Huh7/labels.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/Huh7/images/Huh7_Phase_A12_2_03d04h00m_2.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:54<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        200      11504      0.814      0.749      0.834      0.536      0.796      0.735      0.802      0.461\n",
      "Speed: 0.8ms preprocess, 9.6ms inference, 0.0ms loss, 20.9ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell7\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: MCF7\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/MCF7/labels.cache... 184 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/MCF7/images/MCF7_Phase_H4_1_00d00h00m_2.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:12<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        184      96909      0.856      0.415      0.617      0.354      0.831        0.4      0.592      0.282\n",
      "Speed: 0.4ms preprocess, 4.5ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell8\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: SHSY5Y\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/SHSY5Y/labels.cache... 176 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/SHSY5Y/images/SHSY5Y_Phase_A10_2_03d08h00m_2.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:20<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        176      75982      0.695      0.408      0.535       0.27      0.675      0.384      0.506      0.192\n",
      "Speed: 0.2ms preprocess, 12.3ms inference, 0.0ms loss, 7.2ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell9\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: SkBr3\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/SkBr3/labels.cache... 176 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:34<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        176      65757      0.982      0.712      0.842      0.633      0.962      0.697      0.826      0.475\n",
      "Speed: 0.1ms preprocess, 5.9ms inference, 0.0ms loss, 23.9ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell10\u001b[0m\n",
      "================\n",
      "================\n",
      "marker: SKOV3\n",
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CUDA:1 (Tesla V100-SXM2-32GB, 32501MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning data_yolo_split/SKOV3/labels.cache... 304 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 304/304 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/SKOV3/images/SKOV3_Phase_E4_2_02d16h00m_3.tif: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/SKOV3/images/SKOV3_Phase_E4_2_02d20h00m_3.tif: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ data_yolo_split/SKOV3/images/SKOV3_Phase_E4_2_03d00h00m_4.tif: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:45<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304      47361      0.878      0.807      0.869      0.558      0.885      0.805      0.865      0.502\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.0ms loss, 8.6ms postprocess per image\n",
      "Results saved to \u001b[1mckpts/livecell11\u001b[0m\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each categories on the testing dataset\n",
    "# model = YOLO('./ckpts/livecell/weights/best.pt')\n",
    "\n",
    "MARKERS = ['A172', 'BT474', 'BV2', 'Huh7', 'MCF7', 'SHSY5Y', 'SkBr3', 'SKOV3']\n",
    "\n",
    "output_folder_splits = \"./data_yolo_split\"\n",
    "label_counters = {\n",
    "    marker: convert_coco_json(\n",
    "        image_folder=\"./data_coco/images/livecell_test_images\", \n",
    "        annotation_file=\"./data_coco/livecell_coco_test.json\", \n",
    "        output_folder=os.path.join(output_folder_splits, marker),\n",
    "        keep_fn=lambda x: x.startswith(marker),\n",
    "        use_segments=True\n",
    "    )[0] for marker in MARKERS\n",
    "}\n",
    "# label_counters = {'A172': 32978, 'BT474': 32585, 'BV2': 89970, 'Huh7': 12552, 'MCF7': 96914, 'SHSY5Y': 75988, 'SkBr3': 65757, 'SKOV3': 55517}\n",
    "print(label_counters)\n",
    "print(\"================\")\n",
    "\n",
    "yaml_file_split = [\n",
    "    f\"{marker}: {os.path.join(output_folder_splits, marker, 'images')}\"\n",
    "    for marker in MARKERS\n",
    "] + yaml_file\n",
    "print(\"\\n\".join(yaml_file_split))\n",
    "\n",
    "with open(\"data_livecell_test_split.yaml\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(yaml_file_split))\n",
    "\n",
    "print(\"================\")\n",
    "print(\"Evaluate on testing dataset for each categories:\")\n",
    "\n",
    "test_stats_split = {}\n",
    "for marker in MARKERS:\n",
    "    print(\"================\")\n",
    "    print(f\"marker: {marker}\")\n",
    "    stats = model.val(data='./data_livecell_test_split.yaml', device='cuda:1', split=marker)\n",
    "    test_stats_split[marker] = stats\n",
    "    print(\"================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45342930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Box Precision</th>\n",
       "      <th>Box Recall</th>\n",
       "      <th>Box mAP50</th>\n",
       "      <th>Mask Precision</th>\n",
       "      <th>Mask Recall</th>\n",
       "      <th>Mask mAP50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>livecell</td>\n",
       "      <td>0.839859</td>\n",
       "      <td>0.531477</td>\n",
       "      <td>0.660601</td>\n",
       "      <td>0.824087</td>\n",
       "      <td>0.514530</td>\n",
       "      <td>0.636406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A172</td>\n",
       "      <td>0.760340</td>\n",
       "      <td>0.656983</td>\n",
       "      <td>0.709321</td>\n",
       "      <td>0.779101</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.720566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BT474</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.641849</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.694499</td>\n",
       "      <td>0.615351</td>\n",
       "      <td>0.678568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BV2</td>\n",
       "      <td>0.969109</td>\n",
       "      <td>0.383378</td>\n",
       "      <td>0.627921</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.356257</td>\n",
       "      <td>0.582586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huh7</td>\n",
       "      <td>0.814017</td>\n",
       "      <td>0.748609</td>\n",
       "      <td>0.833508</td>\n",
       "      <td>0.796128</td>\n",
       "      <td>0.735483</td>\n",
       "      <td>0.801921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCF7</td>\n",
       "      <td>0.856477</td>\n",
       "      <td>0.415225</td>\n",
       "      <td>0.617170</td>\n",
       "      <td>0.830692</td>\n",
       "      <td>0.400045</td>\n",
       "      <td>0.592256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHSY5Y</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>0.407860</td>\n",
       "      <td>0.535170</td>\n",
       "      <td>0.674894</td>\n",
       "      <td>0.383726</td>\n",
       "      <td>0.506154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SkBr3</td>\n",
       "      <td>0.981506</td>\n",
       "      <td>0.711574</td>\n",
       "      <td>0.841601</td>\n",
       "      <td>0.962302</td>\n",
       "      <td>0.696808</td>\n",
       "      <td>0.826461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SKOV3</td>\n",
       "      <td>0.878324</td>\n",
       "      <td>0.806580</td>\n",
       "      <td>0.869130</td>\n",
       "      <td>0.884575</td>\n",
       "      <td>0.805093</td>\n",
       "      <td>0.865365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Box Precision  Box Recall  Box mAP50  Mask Precision  \\\n",
       "0  livecell       0.839859    0.531477   0.660601        0.824087   \n",
       "1      A172       0.760340    0.656983   0.709321        0.779101   \n",
       "2     BT474       0.706422    0.641849   0.711405        0.694499   \n",
       "3       BV2       0.969109    0.383378   0.627921        0.902256   \n",
       "4      Huh7       0.814017    0.748609   0.833508        0.796128   \n",
       "5      MCF7       0.856477    0.415225   0.617170        0.830692   \n",
       "6    SHSY5Y       0.694840    0.407860   0.535170        0.674894   \n",
       "7     SkBr3       0.981506    0.711574   0.841601        0.962302   \n",
       "8     SKOV3       0.878324    0.806580   0.869130        0.884575   \n",
       "\n",
       "   Mask Recall  Mask mAP50  \n",
       "0     0.514530    0.636406  \n",
       "1     0.665595    0.720566  \n",
       "2     0.615351    0.678568  \n",
       "3     0.356257    0.582586  \n",
       "4     0.735483    0.801921  \n",
       "5     0.400045    0.592256  \n",
       "6     0.383726    0.506154  \n",
       "7     0.696808    0.826461  \n",
       "8     0.805093    0.865365  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## summarize testing dataset performance into dataframe\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "test_stats_split['livecell'] = test_stats  # add overall performance\n",
    "\n",
    "summary_table = [\n",
    "    {'Dataset': key, \n",
    "     'Box Precision': test_stats_split[key].box.mp,\n",
    "     'Box Recall': test_stats_split[key].box.mr,\n",
    "     'Box mAP50': test_stats_split[key].box.map50, \n",
    "     'Mask Precision': test_stats_split[key].seg.mp,\n",
    "     'Mask Recall': test_stats_split[key].seg.mr,\n",
    "     'Mask mAP50': test_stats_split[key].seg.map50\n",
    "    }\n",
    "    for key in ['livecell'] + MARKERS\n",
    "]\n",
    "display(pd.DataFrame(summary_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6421fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 300 cells, 5.9ms\n",
      "1: 480x640 195 cells, 5.9ms\n",
      "2: 480x640 132 cells, 5.9ms\n",
      "3: 480x640 300 cells, 5.9ms\n",
      "4: 480x640 212 cells, 5.9ms\n",
      "5: 480x640 57 cells, 5.9ms\n",
      "6: 480x640 176 cells, 5.9ms\n",
      "7: 480x640 185 cells, 5.9ms\n",
      "8: 480x640 300 cells, 5.9ms\n",
      "9: 480x640 50 cells, 5.9ms\n",
      "Speed: 1.9ms preprocess, 5.9ms inference, 12.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize instance segmentation on testing images\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(123)\n",
    "\n",
    "test_images = [os.path.join(os.path.join(output_folder_test, \"images\"), file) \n",
    "               for file in os.listdir(os.path.join(output_folder_test, \"images\"))]\n",
    "display_images = random.sample(test_images, 10)\n",
    "results = model(display_images)\n",
    "\n",
    "# Show the results\n",
    "for r in results:\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(18, 18))\n",
    "    plt.imshow(r.plot(font_size=10, labels=False)[...,::-1])  # plot a BGR numpy array of predictions\n",
    "    plt.show()\n",
    "    # im = Image.fromarray(im[..., ::-1])  # RGB PIL image\n",
    "    # im_array.show()  # show image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601830d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.10 ðŸš€ Python-3.11.5 torch-2.1.0+cu118 CPU (Intel Xeon Gold 6240 2.60GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'ckpts/livecell/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 37, 8400), (1, 32, 160, 160)) (22.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'ckpts/livecell/weights/best.onnx' (45.2 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1m/project/DPDS/Xiao_lab/shared/deep_learning_SW_RR/livecell/ckpts/livecell/weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=ckpts/livecell/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=ckpts/livecell/weights/best.onnx imgsz=640 data=./data_livecell.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "## Export the model to ONNX format\n",
    "success = model.export(format='onnx', device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hd_env)",
   "language": "python",
   "name": "hd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
